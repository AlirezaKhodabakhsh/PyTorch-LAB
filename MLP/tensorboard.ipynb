{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# custom libraries\n",
    "root_main = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "import TorchCommon as TC\n",
    "os.chdir(root_main)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# main pyperparametrs\n",
    "valid_size=0.2\n",
    "epochs=1\n",
    "nrm_mean=0.5\n",
    "nrm_std=0.5\n",
    "num_workers=0\n",
    "root_ds = \"D:\\GitHub\\pytorch-lab\\Dataset\" # dataset root\n",
    "root_bm = \"D:\\GitHub\\pytorch-lab\\Best_Models\" # best models root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# transform\n",
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((nrm_mean,) , (nrm_std,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_data=datasets.MNIST(root=root_ds,\n",
    "                          train=True, transform=trans, download=True)\n",
    "\n",
    "test_data=datasets.MNIST(root=root_ds,\n",
    "                          train=False, transform=trans, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "valid_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=valid_sampler)\n",
    "test_loader =DataLoader(test_data,  batch_size= batch_size, num_workers=num_workers, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#sampler\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Network\n",
    "class Net(nn.Module):\n",
    "    # Assign Intrinsic Properties of Your Neural Network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Weights of Layer 1th and Layer 2th Are Intrinsic Properties\n",
    "        self.fc1 = nn.Linear(784, 256, bias=True)\n",
    "        self.fc2 = nn.Linear(256, 100, bias=True)\n",
    "        self.fc3 = nn.Linear(100, 10, bias=True)\n",
    "\n",
    "    # Wiring of Your Network\n",
    "    def feed_forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu_(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu_(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters Searching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.25\tAcc_Train : 0.14\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.34\tAcc_Train : 0.89\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.61\tAcc_Train : 0.83\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.93\tAcc_Train : 0.47\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.49\tAcc_Train : 0.84\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.16\tAcc_Train : 0.72\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.23\tAcc_Train : 0.26\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.30\tAcc_Train : 0.10\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.71\tAcc_Train : 0.51\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.25\tAcc_Train : 0.22\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.31\tAcc_Train : 0.12\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.30\tAcc_Train : 0.12\n"
     ]
    }
   ],
   "source": [
    "#loss_valid_min=np.Inf\n",
    "for batch_size in [2,64,1024]:\n",
    "    for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "        train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "        #create model and set loss function and optimizer\n",
    "        model=Net().to(device)\n",
    "        criterion =nn.CrossEntropyLoss()\n",
    "        optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "        root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "        writer = SummaryWriter(root_tb)\n",
    "\n",
    "        for epoch in range(1,epochs+1):\n",
    "            loss_train, acc_train = TC.train(model,train_loader, device, optimizer, criterion, epoch)\n",
    "            #loss_valid, acc_valid = TC.valid(model, valid_loader, device, criterion)\n",
    "            #loss_valid_min = TC.save_model(model, optimizer, epoch, root_bm, loss_valid_min, loss_valid)\n",
    "\n",
    "            writer.add_scalar(\"train loss\", scalar_value= loss_train, global_step=epoch)\n",
    "            writer.add_scalar(\"train accuracy\", scalar_value= acc_train, global_step=epoch)\n",
    "            writer.add_hparams({'batch_size' : batch_size, 'LR' : lr} , {'Loss' : loss_train, 'Accuracy' : acc_train})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing Dataset Images and Network Weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#loss_valid_min=np.Inf\n",
    "for batch_size in [2]:\n",
    "    for lr in [0.1]:\n",
    "        train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "        #create model and set loss function and optimizer\n",
    "        model=Net().to(device)\n",
    "        criterion =nn.CrossEntropyLoss()\n",
    "        optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "        root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "        writer = SummaryWriter(root_tb)\n",
    "\n",
    "        for epoch in range(1,epochs+1):\n",
    "            loss_train, acc_train = TC.train(model,train_loader, device, optimizer, criterion, epoch)\n",
    "            #loss_valid, acc_valid = TC.valid(model, valid_loader, device, criterion)\n",
    "            #loss_valid_min = TC.save_model(model, optimizer, epoch, root_bm, loss_valid_min, loss_valid)\n",
    "\n",
    "            writer.add_scalar(\"train loss\", scalar_value= loss_train, global_step=epoch)\n",
    "            writer.add_scalar(\"train accuracy\", scalar_value= acc_train, global_step=epoch)\n",
    "            writer.add_hparams({'batch_size' : batch_size, 'LR' : lr} , {'Loss' : loss_train, 'Accuracy' : acc_train})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}