{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# custom libraries\n",
    "root_main = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "import TorchCommon as TC\n",
    "os.chdir(root_main)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# main pyperparametrs\n",
    "valid_size=0.2\n",
    "nrm_mean=0.5\n",
    "nrm_std=0.5\n",
    "num_workers=0\n",
    "root_ds = \"D:\\GitHub\\pytorch-lab\\Dataset\" # dataset root\n",
    "root_bm = \"D:\\GitHub\\pytorch-lab\\Best_Models\" # best models root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# transform\n",
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((nrm_mean,) , (nrm_std,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_data=datasets.MNIST(root=root_ds,\n",
    "                          train=True, transform=trans, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#sampler\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Network\n",
    "class Net(nn.Module):\n",
    "    # Assign Intrinsic Properties of Your Neural Network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Weights of Layer 1th and Layer 2th Are Intrinsic Properties\n",
    "        self.fc1 = nn.Linear(784, 256, bias=True)\n",
    "        self.fc2 = nn.Linear(256, 100, bias=True)\n",
    "        self.fc3 = nn.Linear(100, 10, bias=True)\n",
    "\n",
    "    # Wiring of Your Network\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu_(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu_(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TensorBoard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss/Accuracy Plot (independently)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparaameter\n",
    "epochs=5\n",
    "batch_size=64\n",
    "lr=0.1\n",
    "\n",
    "# TrainLoader\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "# Loss and Optimizer\n",
    "model=Net().to(device)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# TesnorBoard File\n",
    "root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "writer = SummaryWriter(root_tb)\n",
    "\n",
    "# Train\n",
    "step=0\n",
    "for epoch in range(1,epochs+1):\n",
    "    for iter_train, (image, label) in enumerate(train_loader, 1):\n",
    "        # preprocess and feedforward process\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(image)\n",
    "        # we want to track loss/acc\n",
    "        loss = criterion(y_hat, label)\n",
    "        acc = np.count_nonzero(label.to('cpu').numpy() == y_hat.argmax(dim=1).to('cpu').numpy())\n",
    "        # updating process\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.add_scalar(\"Loss Train\", scalar_value= loss, global_step=step)\n",
    "        writer.add_scalar(\"Accuracy Train\", scalar_value= acc, global_step=step)\n",
    "        step+=1\n",
    "        # -NEW- TensorBoard process\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss/Accuracy Plot (hold on)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Hyperparaameter\n",
    "epochs=5\n",
    "batch_size=64\n",
    "lr=0.1\n",
    "\n",
    "# TrainLoader\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "# Loss and Optimizer\n",
    "model=Net().to(device)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# TesnorBoard File\n",
    "root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "writer = SummaryWriter(root_tb)\n",
    "\n",
    "# Train\n",
    "step=0\n",
    "for epoch in range(1,epochs+1):\n",
    "    for iter_train, (image, label) in enumerate(train_loader, 1):\n",
    "        # preprocess and feedforward process\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(image)\n",
    "        # we want to track loss/acc\n",
    "        loss = criterion(y_hat, label)\n",
    "        acc = np.count_nonzero(label.to('cpu').numpy() == y_hat.argmax(dim=1).to('cpu').numpy())\n",
    "        # updating process\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.add_scalars(\"Loss/Accuracy\", {'Loss' : loss, 'Accuracy': acc}, global_step=step)\n",
    "        step+=1\n",
    "        # -NEW- TensorBoard process\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histogram (Parameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Hyperparaameter\n",
    "epochs=5\n",
    "batch_size=64\n",
    "lr=0.1\n",
    "\n",
    "# TrainLoader\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "# Loss and Optimizer\n",
    "model=Net().to(device)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# TesnorBoard File\n",
    "root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "writer = SummaryWriter(root_tb)\n",
    "\n",
    "# Train\n",
    "step=0\n",
    "for epoch in range(1,epochs+1):\n",
    "    for iter_train, (image, label) in enumerate(train_loader, 1):\n",
    "        # preprocess and feedforward process\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(image)\n",
    "        # we want to track loss/acc\n",
    "        loss = criterion(y_hat, label)\n",
    "        acc = np.count_nonzero(label.to('cpu').numpy() == y_hat.argmax(dim=1).to('cpu').numpy())\n",
    "        # updating process\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.add_histogram(\"FC1_Weights\", model.fc1.weight, global_step=step)\n",
    "        writer.add_histogram(\"FC2_Weights\", model.fc2.weight, global_step=step)\n",
    "        writer.add_histogram(\"FC3_Weights\", model.fc3.weight, global_step=step)\n",
    "        step+=1\n",
    "        # -NEW- TensorBoard process\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computation Graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Hyperparaameter\n",
    "batch_size=64\n",
    "\n",
    "# TrainLoader\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "# Loss and Optimizer\n",
    "model=Net()\n",
    "\n",
    "# TesnorBoard File\n",
    "root_tb=f'runs/batch {batch_size}'\n",
    "writer = SummaryWriter(root_tb)\n",
    "\n",
    "# -NEW- TensorBoard process\n",
    "image,label=next(iter(train_loader))\n",
    "writer.add_graph(model, image)\n",
    "# -NEW- TensorBoard process\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### mini-batch images (every iteration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Hyperparaameter\n",
    "epochs=1\n",
    "batch_size=61\n",
    "lr=0.1\n",
    "\n",
    "# TrainLoader\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "# Loss and Optimizer\n",
    "model=Net().to(device)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# TesnorBoard File\n",
    "root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "writer = SummaryWriter(root_tb)\n",
    "\n",
    "# Train\n",
    "step=0\n",
    "for epoch in range(1,epochs+1):\n",
    "    for iter_train, (image, label) in enumerate(train_loader, 1):\n",
    "        # preprocess and feedforward process\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(image)\n",
    "        # we want to track loss/acc\n",
    "        loss = criterion(y_hat, label)\n",
    "        acc = np.count_nonzero(label.to('cpu').numpy() == y_hat.argmax(dim=1).to('cpu').numpy())\n",
    "        # updating process\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.add_images(\"mini=batch data\", image, global_step=iter_train)\n",
    "        step+=1\n",
    "        # -NEW- TensorBoard process\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### mini-batch signals (every iteration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters Searching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.40\tAcc_Train : 0.87\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.49\tAcc_Train : 0.86\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.50\tAcc_Train : 0.60\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 0.59\tAcc_Train : 0.81\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.43\tAcc_Train : 0.65\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.27\tAcc_Train : 0.22\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 1.67\tAcc_Train : 0.52\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.26\tAcc_Train : 0.20\n",
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n",
      "Loss_Train: 2.30\tAcc_Train : 0.12\n"
     ]
    }
   ],
   "source": [
    "# Hyperparaameter\n",
    "epochs=1\n",
    "for batch_size in [10,100,1000]:\n",
    "    for lr in [0.1, 0.01, 0.001]:\n",
    "        # TrainLoader\n",
    "        train_loader=DataLoader(train_data, batch_size= batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "\n",
    "        # Loss and Optimizer\n",
    "        model=Net().to(device)\n",
    "        criterion =nn.CrossEntropyLoss()\n",
    "        optimizer=optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # TesnorBoard File\n",
    "        root_tb=f'runs/batch {batch_size} LR {lr}'\n",
    "        writer = SummaryWriter(root_tb)\n",
    "\n",
    "        # Train\n",
    "        for epoch in range(1,epochs+1):\n",
    "            loss_train, acc_train = TC.train(model,train_loader, device, optimizer, criterion, epoch)\n",
    "\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.add_hparams({'batch_size' : batch_size, 'LR' : lr} ,\n",
    "                           {'Loss train' : loss_train, 'Accuracy train' : acc_train})\n",
    "        # -NEW- TensorBoard process\n",
    "        writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Embedding Projector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# desired datas that you want visualize\n",
    "images, labels = train_data.data[:1000], train_data.targets[:1000]\n",
    "# make TB file\n",
    "writer = SummaryWriter(f\"runs\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# create \"image labels\" for classes.\n",
    "label_image  = torch.unsqueeze(images,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# create \"name labels\" for class.\n",
    "label_name=['0','1','2','3','4','5','6','7','8','9']\n",
    "# replace every 0,1 label with related string\n",
    "label_name = [label_name[lab] for lab in labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Features (Dimensions)\n",
    "features = torch.flatten(images, start_dim=1).to(torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "writer.add_embedding(features,\n",
    "                    metadata=label_name,\n",
    "                     label_img =label_image )\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}